<p align="center">
  <h1 align="center">
  Awesome SLAM for Legged Robot 
  </h1>
</p>

This repository contains a curated list of resources addressing the SLAM methods specially designed for humanoid /quadruped robots. 

If you find some ignored papers, **feel free to [*create pull requests*](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM/blob/pdf/How-to-PR.md), or [*open issues*](https://github.com/KwanWaiPang/Humanoid-Robot-Localization-and-Mapping/issues/new)**. 

Contributions in any form to make this list more comprehensive are welcome.

If you find this repository useful, a simple star should be the best affirmation. üòä

Feel free to share this list with others!


<div align="center">
<img src="https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/raw/pdf/Legged%20Robot.jpg" width="52%" />
<img src="https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/raw/pdf/Humanoid%20robot.jpg" width="40%" />
</div>
<div align="center">
    The right-hand side image is generated by ChatGPT
</div>

# Papers

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`RAS`|[Terrain-based place recognition for LiDAR SLAM of quadruped robots with limited field-of-view measurements](https://www.sciencedirect.com/science/article/pii/S0921889025004129)|---|---|
|2025|`TRO`|[MARG: MAstering Risky Gap Terrains for Legged Robots with Elevation Mapping](https://arxiv.org/pdf/2509.20036)|---|[website](https://astrorix.github.io/MARG/)| 
|2025|`RAL`|[LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://ieeexplore.ieee.org/abstract/document/11123716)|---|---|
|2025|`IROS`|[GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial and Legged Odometry Fusion SLAM for Dynamic Legged Robotics](https://arxiv.org/pdf/2503.14247)|[![Github stars](https://img.shields.io/github/stars/HorizonRobotics/GeoFlowSlam.svg)](https://github.com/HorizonRobotics/GeoFlowSlam)|---|
|2025|`RAL`|[Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information](https://arxiv.org/pdf/2506.09548?)|---|[website](https://takuokawara.github.io/RAL2025_project_page/)|
|2025|`IEEE Internet of Things Journal`|[An Inertial Odometry and Enhanced Occupancy Grid Inertial SLAM for Legged Robots](https://ieeexplore.ieee.org/abstract/document/11030803)|---|---|
|2025|`arXiv`|[Holistic Fusion: Task-and Setup-Agnostic Robot Localization and State Estimation with Factor Graphs](https://arxiv.org/pdf/2504.06479)|[![Github stars](https://img.shields.io/github/stars/leggedrobotics/holistic_fusion.svg)](https://github.com/leggedrobotics/holistic_fusion)|[website](https://leggedrobotics.github.io/holistic_fusion/)| 
|2025|`IEEE Signal Processing Letters`|[A 3D reconstruction and relocalization method for humanoid welding robots](https://ieeexplore.ieee.org/abstract/document/10900432)|---|---|
|2024|`arXiv`|[Navila: Legged robot vision-language-action model for navigation](https://arxiv.org/pdf/2412.04453)|[![Github stars](https://img.shields.io/github/stars/yang-zj1026/legged-loco.svg)](https://github.com/yang-zj1026/legged-loco)|[website](https://navila-bot.github.io/)|
|2024|`RAL`|[Leg-KILO: Robust Kinematic-Inertial-Lidar Odometry for Dynamic Legged Robots](https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/blob/pdf/Leg-KILO%20Robust%20Kinematic-Inertial-Lidar%20Odometry%20for%20Dynamic%20Legged%20Robots.pdf)|[![Github stars](https://img.shields.io/github/stars/ouguangjun/Leg-KILO.svg)](https://github.com/ouguangjun/Leg-KILO)|[dataset](https://github.com/ouguangjun/legkilo-dataset)|
|2024|`ICRA`|[Optistate: State estimation of legged robots using gated networks with transformer-based vision and kalman filtering](https://arxiv.org/pdf/2401.16719)|[![Github stars](https://img.shields.io/github/stars/AlexS28/OptiState.svg)](https://github.com/AlexS28/OptiState)|---|
|2023|`IROS`|[Multi-IMU Proprioceptive Odometry For Legged Robots](https://rexlab.ri.cmu.edu/papers/foot_imu_iros2023.pdf)|[![Github stars](https://img.shields.io/github/stars/ShuoYangRobotics/Multi-IMU-Proprioceptive-Odometry.svg)](https://github.com/ShuoYangRobotics/Multi-IMU-Proprioceptive-Odometry)|---|
|2023|`ICRA`|[Visual-inertial and leg odometry fusion for dynamic locomotion](https://arxiv.org/pdf/2210.02127)|---|---| 
|2023|`ICRA`|[Cerberus: Low-drift visual-inertial-leg odometry for agile locomotion](https://arxiv.org/pdf/2209.07654)|[![Github stars](https://img.shields.io/github/stars/ShuoYangRobotics/Cerberus.svg)](https://github.com/ShuoYangRobotics/Cerberus)|Cerberus2.0 <br> [![Github stars](https://img.shields.io/github/stars/ShuoYangRobotics/Cerberus2.0.svg)](https://github.com/ShuoYangRobotics/Cerberus2.0) |
|2023|`RAL`|[Tunable impact and vibration absorbing neck for robust visual-inertial state estimation for dynamic legged robots](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10027207)|---|---|
|2023|`TRO`|[Invariant smoother for legged robot state estimation with dynamic contact event information](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10301546)|---|---|
|2023|`International Conference on Robotics and Mechatronics`|[Comparative evaluation of rgb-d slam methods for humanoid robot localization and mapping](https://arxiv.org/pdf/2401.02816)|---|---|
|2023|`TASE`|[Humanoid loco-manipulations using combined fast dense 3D tracking and SLAM with wide-angle depth-images](https://hal.science/hal-04125159v1/file/2023_TASE_Chappellet.pdf)|---|---|
|2022|`ICRA`|[Periodic SLAM: Using cyclic constraints to improve the performance of visual-inertial SLAM on legged robots](https://par.nsf.gov/servlets/purl/10335323)|---|[video](https://www.youtube.com/watch?v=QygyDjVy5nY)|
|2022|`RAL`|[LAMP 2.0: A robust multi-robot SLAM system for operation in challenging large-scale underground environments](https://arxiv.org/pdf/2205.13135)|[![Github stars](https://img.shields.io/github/stars/NeBula-Autonomy/LAMP.svg)](https://github.com/NeBula-Autonomy/LAMP)|[dataset](https://github.com/NeBula-Autonomy/nebula-multirobot-dataset)|
|2022|`RAL`|[Online kinematic calibration for legged robots](https://rexlab.ri.cmu.edu/papers/onlinecalib.pdf)|---|---|
|2022|`TRO`|[Vilens: Visual, inertial, lidar, and leg odometry for all-terrain legged robots](https://arxiv.org/pdf/2107.07243)|---|---|
|2022|`TRO`|[Rloc: Terrain-aware legged locomotion using reinforcement learning and optimal control](https://arxiv.org/pdf/2012.03094)|---|---|
|2022|`RAL`|[Step: State estimator for legged robots using a preintegrated foot velocity factor](https://arxiv.org/pdf/2202.05572)|---|---|
|2022|`Conference on robot learning`|[Learning inertial odometry for dynamic legged robot state estimation](https://proceedings.mlr.press/v164/buchanan22a/buchanan22a.pdf)|---|---| 
|2022|`arXiv`|[A1 SLAM: Quadruped SLAM using the A1's Onboard Sensors](https://arxiv.org/pdf/2211.14432)|[![Github stars](https://img.shields.io/github/stars/jerredchen/A1_SLAM.svg)](https://github.com/jerredchen/A1_SLAM)|---|
|2021|`arXiv`|[WALK-VIO: Walking-motion-adaptive leg kinematic constraint visual-inertial odometry for quadruped robots](https://arxiv.org/pdf/2111.15164)|---|---|
|2021|`IEEE Sensors Letters`|[On state estimation for legged locomotion over soft terrain](https://arxiv.org/pdf/2101.02279)|---|---|
|2021|`ICRA`|[Legged robot state estimation in slippery environments using invariant extended kalman filter with velocity update](https://arxiv.org/pdf/2104.04238)|---|[video](https://www.youtube.com/watch?v=VIqJL0cUr7s)| 
|2021|`ICRA`|[Contact forces preintegration for estimation in legged robotics using factor graphs](https://hal.science/hal-02991717v1/file/ICRA_2021_MFourmy.pdf)|---|---| 
|2021|`RAL`|[Legged robot state estimation with dynamic contact event information](https://ieeexplore.ieee.org/abstract/document/9468900)|---|---|
|2021|`RAL`|[Online Object Searching by a Humanoid Robot in an Unknown Environment](https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/blob/pdf/2021_RAL_Tsuru.pdf)|---|---|
|2020|`ICRA`|[Preintegrated velocity bias estimation to overcome contact nonlinearities in legged robot odometry](https://arxiv.org/pdf/1910.09875)|---|---|
|2020|`Frontiers in Robotics and AI`|[Pronto: A multi-sensor state estimator for legged robots in real-world scenarios](https://www.robots.ox.ac.uk/~mobile/drs/Papers/2020FRONTIERS_camurri.pdf)|[![Github stars](https://img.shields.io/github/stars/ori-drs/pronto.svg)](https://github.com/ori-drs/pronto)|---|
|2020|`IJRR`|[Contact-aided invariant extended Kalman filtering for robot state estimation](https://journals.sagepub.com/doi/pdf/10.1177/0278364919894385?casa_token=dzctF2F3Nb0AAAAA:c21qyyoA6KtBcnsRO6CBHSlcO0lBt6rtxFU16tLmTK3jVOjdlr4x5cMtWF1fLuaf6YSFROwK7vA_N4A)|[![Github stars](https://img.shields.io/github/stars/RossHartley/invariant-ekf.svg)](https://github.com/RossHartley/invariant-ekf)|---| 
|2019|`RAL`|[Dynamic locomotion on slippery ground](https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/355281/1/IROS19___Dynamic_Locomotion_on_Slippery_Ground.pdf)|---|---|
|2019|`IEEE-RAS 19th international conference on humanoid robots`|[Footstep planning for autonomous walking over rough terrain](https://arxiv.org/pdf/1907.08673)|---|---|
|2019|`RAL`|[Robust legged robot state estimation using factor graph optimization](https://arxiv.org/pdf/1904.03048)|---|[video](https://www.youtube.com/watch?v=p8o7mJPy4_w)|
|2019|`IROS`|[Humanoid robot next best view planning under occlusions using body movement primitives](https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/blob/pdf/Humanoid_Robot_Next_Best_View_Planning_Under_Occlusions_Using_Body_Movement_Primitives.pdf)|---|---|
|2018|`RSS`|[Contact-Aided Invariant Extended Kalman Filtering for Legged Robot State Estimation](https://arxiv.org/pdf/1805.10410)|[![Github stars](https://img.shields.io/github/stars/RossHartley/invariant-ekf.svg)](https://github.com/RossHartley/invariant-ekf)|---|
|2018|`IROS`|[Hybrid contact preintegration for visual-inertial-contact state estimation using factor graphs](https://arxiv.org/pdf/1803.07531)|---|---|
|2018|`Mechatronics`|[Novel lightweight odometric learning method for humanoid robot localization](https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/blob/pdf/1-s2.0-S0957415818301338-main.pdf)|---|---|
|2018|`IROS`|[Mit cheetah 3: Design and control of a robust, dynamic quadruped robot](https://dspace.mit.edu/bitstream/handle/1721.1/126619/iros.pdf?sequence=2)|---|---|
|2018|`ICRA`|[Legged robot state-estimation through combined forward kinematic and preintegrated contact factors](https://arxiv.org/pdf/1712.05873)|---|---|
|2017|`RSS`|[Heterogeneous sensor fusion for accurate state estimation of dynamic legged robots](https://www.pure.ed.ac.uk/ws/portalfiles/portal/36374655/NobiliCamurriRSS17_3.pdf)|[![Github stars](https://img.shields.io/github/stars/ori-drs/pronto.svg)](https://github.com/ori-drs/pronto) |---|
|2017|`Ph.D. dissertation`|[State estimation for legged robots-kinematics, inertial sensing, and computer vision](https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/129873/ETH24130.pdf)|---|---|
|2017|`IEEE-RAS 17th International Conference on Humanoid Robotics`|[Efficient coverage of 3D environments with humanoid robots using inverse reachability maps](https://www.cs.columbia.edu/~allen/S19/Student_Papers/coverage_nao_environment.pdf)|---|---|
|2017|`Intelligent Service Robotics`|[A closed-loop approach for tracking a humanoid robot using particle filtering and depth data](https://upcommons.upc.edu/bitstream/handle/2117/107765/ISR2016v2-CR-submitted.pdf?sequence=1)|---|---| 
|2017|`RAL`|[Probabilistic contact estimation and impact detection for state estimation of quadruped robots](https://robots.ox.ac.uk/~mfallon/publications/2017RAL_camurri.pdf)|---|---|
|2016|`Autonomous robots`|[Optimization-based locomotion planning, estimation, and control design for the atlas humanoid robot](https://www.researchgate.net/profile/Hongkai-Dai/publication/282477851_Optimization-based_locomotion_planning_estimation_and_control_design_for_the_atlas_humanoid_robot/links/5614501f08ae983c1b4073ac/Optimization-based-locomotion-planning-estimation-and-control-design-for-the-atlas-humanoid-robot.pdf)|---|---|
|2016|`IJRR`|[Real-time pose estimation of a dynamic quadruped in GPS-denied environments for 24-hour operation](https://journals.sagepub.com/doi/pdf/10.1177/0278364915587333?casa_token=yLMhh0p_DsoAAAAA:28GnrhizmgotGH4q0DjWKNXJnA4lb-21GdjpeXJDKsDSdDjJg_FPlt9vHaH_XOC4rYfCKER32UXaoAY)|---|---| 
|2016|`IROS`|[Probabilistic foot contact estimation by fusing information from dynamics and differential/forward kinematics](https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/119957/1/eth-49681-01.pdf)|---|---|
|2016|`IROS`|[Achievement of localization system for humanoid robots with virtual horizontal scan relative to improved odometry fusing internal sensors and visual information](https://github.com/KwanWaiPang/Awesome-Legged-Robot-Localization-and-Mapping/blob/pdf/Achievement_of_localization_system_for_humanoid_robots_with_virtual_horizontal_scan_relative_to_improved_odometry_fusing_internal_sensors_and_visual_information.pdf)|---|---|
|2016|`Autonomous Robots`|[Humanoid odometric localization integrating kinematic, inertial and visual information](https://iris.uniroma1.it/bitstream/11573/796335/6/796335.pdf)|---|---|
|2016|`IEEE/SICE International Symposium on System Integration`|[Closed-loop RGB-D SLAM multi-contact control for humanoid robots](https://hal.science/hal-01568048v1/file/iis2016.pdf)|---|---|
|2016|`ICRA`|[Learning the odometry on a small humanoid robot](https://www.researchgate.net/profile/Steve-Nguyen-2/publication/303885984_Learning_the_odometry_on_a_small_humanoid_robot/links/59e0f7af0f7e9b97fbe1382f/Learning-the-odometry-on-a-small-humanoid-robot.pdf)|[![Github stars](https://img.shields.io/github/stars/Rhoban/IKWalk.svg)](https://github.com/Rhoban/IKWalk)|---|
|2015|`IROS`|[Multimodal sensor fusion for foot state estimation in bipedal robots using the extended kalman filter](https://ieeexplore.ieee.org/abstract/document/7353746/)|---|---|
|2015|`International Journal of Humanoid Robotics`|[Estimation and stabilization of humanoid flexibility deformation using only inertial measurement units and contact information](https://hal.science/hal-01169149/document)|---|---| 
|2015|`Advanced Robotics`|[Dead reckoning for biped robots that suffers less from foot contact condition based on anchoring pivot estimation](https://www.tandfonline.com/doi/pdf/10.1080/01691864.2015.1011694)|---|---|
|2014|`IROS`|[Dynamic state estimation using quadratic programming](http://www.cs.cmu.edu/~sfeng/xx_iros14.pdf)|---|---|
|2014|`IROS`|[State estimation for a humanoid robot](https://arxiv.org/pdf/1402.5450)|---|---| 
|2014|`IEEE-RAS International Conference on Humanoid Robots`|[Drift-free humanoid state estimation fusing kinematic, inertial and lidar sensing](https://www.pure.ed.ac.uk/ws/portalfiles/portal/18903340/14_fallon_humanoids.pdf)|---|---|
|2013|`IROS`|[State estimation for legged robots on unstable and slippery terrain](https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/75852/eth-7743-01.pdf)|---|---|
|2013|`Robotics`|[State estimation for legged robots-consistent fusion of leg kinematics and IMU](https://infoscience.epfl.ch/server/api/core/bitstreams/bb6c046d-6633-4c8c-8a5f-f8729667c6b6/content)|---|---|
|2012|`IEEE-RAS International Conference on Humanoid Robots`|[Vision-based odometric localization for humanoids using a kinematic EKF](http://www.diag.uniroma1.it/~labrob/pub/papers/Humanoids2012.pdf)|---|---| 
|2010|`IEEE/RSJ International Conference on Intelligent Robots and Systems`|[Humanoid robot localization in complex indoor environments](http://www2.informatik.uni-freiburg.de/~wurm/papers/hornung10iros.pdf)|---|---|
|2009|`IEEE-RAS International Conference on Humanoid Robots`|[3D grid and particle based SLAM for a humanoid robot](https://ieeexplore.ieee.org/abstract/document/5379602)|---|---|
|2008|`IEEE-RAS International Conference on Humanoid Robots`|[Autonomous humanoid navigation using laser and odometry data](https://d1wqtxts1xzle7.cloudfront.net/84814066/navigation2008-libre.pdf?1650840576=&response-content-disposition=inline%3B+filename%3DAutonomous_humanoid_navigation_using_las.pdf&Expires=1742998314&Signature=PhG-Jac79p3DdteQuhFeKYbJZhHd01wTVhFGRVwaI3-4XHejDUzPm1bwtv6fHNIMK~ePhalBmacKGeJgh7nMPlNQ44VsY2JojP0dEdnwtdbgpL3JDl6I5gzMRpNDPmwxUQTo8gzIMYpZx5WVccgNizHM7bu0gk1oHP8Zz~Nq5JOwgKim1dI77wvu2pQeVWxv9TyFr0BjXus4p23lx3gA6PLtRqddiwJJ0Sd1plMa-EVRpc3KtvbFdIRgUBtRnm8y37TeAw6PtwWpQ~-4ODqrpEC5M-4Ys1Y9ACnaRU6YVolOkZRYdG~MguXeB8Bg1ElCJhhqxXH49ZoHwH6XOUMtvA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)|---|---|
|2006|`IEEE-RAS International Conference on Humanoid Robots`|[Localisation for autonomous humanoid navigation](https://ieeexplore.ieee.org/abstract/document/4115574)|---|---|
|2006|`IEEE/RSJ International Conference on Intelligent Robots and Systems`|[Real-time 3d slam for humanoid robot considering pattern generator information](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=8f13256fa676153aafccad3e32dabbfec1fce32a)|---|---|
|2005|`IEEE-RAS International Conference on Humanoid Robots`|[Humanoid robot localisation using stereo vision](https://ieeexplore.ieee.org/abstract/document/1573539/)|---|---|
|2005|`TRO`|[A leg configuration measurement system for full-body pose estimates in a hexapod robot](https://core.ac.uk/download/pdf/76389503.pdf)|---|---|




# Related Resource
* Survey for Learning-based VO,VIO,IOÔºö[Paper List](https://github.com/KwanWaiPang/Awesome-Learning-based-VO-VIO) 
* Survey for Transformer-based SLAMÔºö[Paper List](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM) 
* Survey for Diffusion-based SLAMÔºö[Paper List](https://github.com/KwanWaiPang/Awesome-Diffusion-based-SLAM) 
* Survey for NeRF-based SLAMÔºö[Blog](https://blog.csdn.net/gwplovekimi/article/details/135083274)
* Survey for 3DGS-based SLAM: [Blog](https://kwanwaipang.github.io/3DGS-SLAM/)
* Survey for Deep IMU-Bias Inference [Blog](https://kwanwaipang.github.io/Deep-IMU-Bias/)
* Paper Survey for Degeneracy of LiDAR-SLAM [Blog](https://kwanwaipang.github.io/Lidar_Degeneracy/)
* Paper Survey for dynamic SLAM [Blog](https://kwanwaipang.github.io/Dynamic-SLAM/)
* Reproduction and Learning for LOAM Series [Blog](https://blog.csdn.net/gwplovekimi/article/details/119711762?spm=1001.2014.3001.5502)
* [Awesome-LiDAR-Visual-SLAM](https://github.com/sjtuyinjie/awesome-LiDAR-Visual-SLAM)
* [Awesome-LiDAR-Camera-Calibration](https://github.com/Deephome/Awesome-LiDAR-Camera-Calibration)
* FAST_LIO_LOCALIZATION_HUMANOID: [Github](https://github.com/deepglint/FAST_LIO_LOCALIZATION_HUMANOID)
* Overview of Humanoid RobotsÔºö

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->
| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[Humanoid locomotion and manipulation: Current progress and challenges in control, planning, and learning](https://arxiv.org/pdf/2501.02116)|---|---|
|2024|`IEEE/CAA Journal of Automatica Sinica`|[Advancements in humanoid robots: A comprehensive review and future prospects](https://www.ieee-jas.net/article/doi/10.1109/JAS.2023.124140)|---|---|
|2024|`arXiv`|[Exbody2: Advanced expressive humanoid whole-body control](https://arxiv.org/pdf/2412.13196?)|---|[website](https://exbody2.github.io/)| 
|2024|`CoRL`|[Visual whole-body control for legged loco-manipulation](https://arxiv.org/pdf/2403.16967)|[![Github stars](https://img.shields.io/github/stars/Ericonaldo/visual_wholebody.svg)](https://github.com/Ericonaldo/visual_wholebody)|[website](https://wholebody-b1.github.io/)|
|2022|`Field Robotics`|[Cerberus: Autonomous legged and aerial robotic exploration in the tunnel and urban circuits of the darpa subterranean challenge](https://d1wqtxts1xzle7.cloudfront.net/84655738/2201.07067-libre.pdf?1650599141=&response-content-disposition=inline%3B+filename%3DCERBERUS_Autonomous_Legged_and_Aerial_Ro.pdf&Expires=1743056230&Signature=Kau5sbITIQY8t44-b22CcAmkb0ODESA4oYnMPghfJLqMrtO-ZVxKvacw0zHU-zJ59NcQ2l8mHEbBQXp55sXoSJWg6CTO52KY2Hwd3Bo3hs1UfW8WhStxS-mQmDPF-AFqlgBjuH8iwrOtVETkUuUuOlf8iPGSlvQpNurkGUftuF70esjD~Yex-fyQlmIOX0xazfrE8IAnAlrHV7E94lpD7cvNOnDtQvL6kBq7Je8owcH2ikqcJBIDe1yUbO42S~dC5J50aR57mO0cy61PdUl2hxcNnSnF8yFcEgDrRrIDcaI5ULF4NFQR0jODcS0evpmag~dmfOmgU4dQkbDj04AQIA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)|---|---| 

* Some Excellent 3D SLAM Works:

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`SRO`|[Resilient odometry via hierarchical adaptation](https://www.science.org/stoken/author-tokens/ST-3125/full)|[![Github stars](https://img.shields.io/github/stars/superxslam/SuperOdom.svg)](https://github.com/superxslam/SuperOdom) |[website](https://superodometry.com/)<br>Super Odometry,ÊåâÈúÄÂàÜÂ±ÇÊú∫Âà∂1. Ëá™ÈÄÇÂ∫îÁâπÂæÅÈÄâÊã©(ÈíàÂØπËßÜËßâÈÄÄÂåñÔºå‰ºòÂÖàËøáÊª§Êéâ‰∏çÂèØÈù†ÁöÑËßÜËßâËßÇÊµã)Ôºõ2„ÄÅËá™ÈÄÇÂ∫îÁä∂ÊÄÅÊñπÂêëÈÄâÊã©ÔºàÈíàÂØπÈõ∑ËææÈÄÄÂåñÔºåËØÜÂà´Âπ∂Ë°•Âº∫ÊúÄÂº±ÁöÑ‰ΩçÂßøÊñπÂêëÔºâÔºõ3„ÄÅËá™ÈÄÇÂ∫îÂºïÊìéÔºàÂõ†Â≠êÔºâÈÄâÊã©ÔºàÈíàÂØπËßÜËßâ‰∏éÈõ∑ËææÈÉΩÈÄÄÂåñÁöÑÂú∫ÊôØÔºåÂä®ÊÄÅÂÜ≥ÂÆöÂì™‰∫õ‰º†ÊÑüÂô®Âõ†Â≠êÂ∫îÂèÇ‰∏é‰ºòÂåñÔºâÔºõ4„ÄÅLearning-based IMU odometryÔºàÂÆåÂÖ®ÈÄÄÂåñÊó∂ÔºåIMUÊé•ÁÆ°Ôºå‰Ωú‰∏∫ÂÖúÂ∫ï,ËÆ≠ÁªÉÊï∞ÊçÆË¶ÜÁõñËΩÆÂºè„ÄÅËÖøÂºè„ÄÅÊó†‰∫∫Êú∫„ÄÅÊâãÊåÅËÆæÂ§áÁ≠âÂ§öÁßçËΩΩ‰ΩìÔºåÊÄªÊó∂ÈïøË∂ÖËøá¬†100¬†Â∞èÊó∂ÔºâÔºâ|
|2025|`TRO`|[OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS](https://arxiv.org/pdf/2510.04612)|[![Github stars](https://img.shields.io/github/stars/ethz-mrl/OKVIS2-X.svg)](https://github.com/ethz-mrl/OKVIS2-X)|---|
|2025|`RAL`|[Voxel-SVIO: Stereo Visual-Inertial Odometry based on Voxel Map](https://ieeexplore.ieee.org/abstract/document/10993347/)|[![Github stars](https://img.shields.io/github/stars/ZikangYuan/voxel_svio.svg)](https://github.com/ZikangYuan/voxel_svio)|---| 
|2024|`TPAMI`|[R3LIVE++: A Robust, Real-time, Radiance Reconstruction Package with a Tightly-coupled LiDAR-Inertial-Visual State Estimator](https://arxiv.org/pdf/2209.03666)|[![Github stars](https://img.shields.io/github/stars/hku-mars/r3live.svg)](https://github.com/hku-mars/r3live)|dataset [![Github stars](https://img.shields.io/github/stars/ziv-lin/r3live_dataset.svg)](https://github.com/ziv-lin/r3live_dataset)|
|2023|`IROS`|[Event camera-based visual odometry for dynamic motion tracking of a legged robot using adaptive time surface](https://arxiv.org/pdf/2305.08962)|---|[demo](https://www.youtube.com/watch?v=-5ieQSh0g3M&feature=youtu.be)|
|2022|`ICRA`|[R3LIVE: A Robust, Real-time, RGB-colored, LiDAR-Inertial-Visual tightly-coupled state Estimation and mapping package](https://arxiv.org/pdf/2109.07982)|[![Github stars](https://img.shields.io/github/stars/hku-mars/r3live.svg)](https://github.com/hku-mars/r3live)|---|
|2021|`RAL`|[R2LIVE: A Robust, Real-Time, LiDAR-Inertial-Visual Tightly-Coupled State Estimator and Mapping](https://arxiv.org/pdf/2102.12400)|[![Github stars](https://img.shields.io/github/stars/hku-mars/r2live.svg)](https://github.com/hku-mars/r2live)|---|
|2024|`TRO`|[FAST-LIVO2: Fast, Direct LiDAR‚ÄìInertial‚ÄìVisual Odometry](https://arxiv.org/pdf/2408.14035)|[![Github stars](https://img.shields.io/github/stars/hku-mars/FAST-LIVO2.svg)](https://github.com/hku-mars/FAST-LIVO2)|---|
|2022|`IROS`|[Fast-livo: Fast and tightly-coupled sparse-direct lidar-inertial-visual odometry](https://arxiv.org/pdf/2203.00893)|[![Github stars](https://img.shields.io/github/stars/hku-mars/FAST-LIVO.svg)](https://github.com/hku-mars/FAST-LIVO)|---|
|2023|`TRO`|[Immesh: An immediate lidar localization and meshing framework](https://arxiv.org/pdf/2301.05206)|[![Github stars](https://img.shields.io/github/stars/hku-mars/ImMesh.svg)](https://github.com/hku-mars/ImMesh)|---|
|2023|`Advanced Intelligent Systems`|[Point‚ÄêLIO: Robust high‚Äêbandwidth light detection and ranging inertial odometry](https://advanced.onlinelibrary.wiley.com/doi/pdf/10.1002/aisy.202200459)|[![Github stars](https://img.shields.io/github/stars/hku-mars/Point-LIO.svg)](https://github.com/hku-mars/Point-LIO)|---|
|2022|`RAL`|[Ctrl-VIO: Continuous-time visual-inertial odometry for rolling shutter cameras](https://arxiv.org/pdf/2208.12008)|[![Github stars](https://img.shields.io/github/stars/APRIL-ZJU/Ctrl-VIO.svg)](https://github.com/APRIL-ZJU/Ctrl-VIO)|---|
|2022|`TRO`|[FAST-LIO2: Fast Direct LiDAR-inertial Odometry](https://arxiv.org/pdf/2107.06829)|[![Github stars](https://img.shields.io/github/stars/hku-mars/FAST_LIO.svg)](https://github.com/hku-mars/FAST_LIO)|---| 
|2021|`RAL`|[Fast-lio: A fast, robust lidar-inertial odometry package by tightly-coupled iterated kalman filter](https://arxiv.org/pdf/2010.08196)|[![Github stars](https://img.shields.io/github/stars/hku-mars/FAST_LIO.svg)](https://github.com/hku-mars/FAST_LIO)|---|
|2019|`JFR`|[RTAB‚ÄêMap as an open‚Äêsource lidar and visual simultaneous localization and mapping library for large‚Äêscale and long‚Äêterm online operation](https://arxiv.org/pdf/2403.06341)|[![Github stars](https://img.shields.io/github/stars/introlab/rtabmap.svg)](https://github.com/introlab/rtabmap)|---| 
|2019|`ICRA`|[Tightly coupled 3d lidar inertial odometry and mapping](https://arxiv.org/pdf/1904.06993)|[![Github stars](https://img.shields.io/github/stars/hyye/lio-mapping.svg)](https://github.com/hyye/lio-mapping)|LIO-Mapping|
|2018|`IROS`|[Scan context: Egocentric spatial descriptor for place recognition within 3d point cloud map](https://gisbi-kim.github.io/publications/gkim-2018-iros.pdf)|[![Github stars](https://img.shields.io/github/stars/gisbi-kim/SC-LIO-SAM.svg)](https://github.com/gisbi-kim/SC-LIO-SAM)|SC-LIO-SAM| 
|2021|`ICRA`|[Lvi-sam: Tightly-coupled lidar-visual-inertial odometry via smoothing and mapping](https://arxiv.org/pdf/2104.10831)|[![Github stars](https://img.shields.io/github/stars/TixiaoShan/LVI-SAM.svg)](https://github.com/TixiaoShan/LVI-SAM)|---|
|2020|`IROS`|[Lio-sam: Tightly-coupled lidar inertial odometry via smoothing and mapping](https://arxiv.org/pdf/2007.00258)|[![Github stars](https://img.shields.io/github/stars/TixiaoShan/LIO-SAM.svg)](https://github.com/TixiaoShan/LIO-SAM)|---| 
|2018|`IROS`|[Lego-loam: Lightweight and ground-optimized lidar odometry and mapping on variable terrain](https://static.ux5.de/Moving-Object-Detection-with-OpenCV/archiv/learnopencv-master/LeGO-LOAM-ROS2/Shan_Englot_IROS_2018_Preprint.pdf)|[![Github stars](https://img.shields.io/github/stars/RobustFieldAutonomyLab/LeGO-LOAM.svg)](https://github.com/RobustFieldAutonomyLab/LeGO-LOAM)|---| 
|2020|`ICRA`|[Loam livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV](https://arxiv.org/pdf/1909.06700)|[![Github stars](https://img.shields.io/github/stars/hku-mars/loam_livox.svg)](https://github.com/hku-mars/loam_livox)|---|
|2022|`TRO`|[GVINS: Tightly coupled GNSS‚Äìvisual‚Äìinertial fusion for smooth and consistent state estimation](https://arxiv.org/pdf/2103.07899)|[![Github stars](https://img.shields.io/github/stars/HKUST-Aerial-Robotics/GVINS.svg)](https://github.com/HKUST-Aerial-Robotics/GVINS)|---|
|2019|`arXiv`|[A General Optimization-based Framework for Global Pose Estimation with Multiple Sensors](https://arxiv.org/pdf/1901.03642)|[![Github stars](https://img.shields.io/github/stars/HKUST-Aerial-Robotics/VINS-Fusion.svg)](https://github.com/HKUST-Aerial-Robotics/VINS-Fusion)|VINS-Fusion|
|2018|`TRO`|[Vins-mono: A robust and versatile monocular visual-inertial state estimator](https://arxiv.org/pdf/1708.03852)|[![Github stars](https://img.shields.io/github/stars/HKUST-Aerial-Robotics/VINS-Mono.svg)](https://github.com/HKUST-Aerial-Robotics/VINS-Mono) |---|
|2014|`RSS`|[LOAM: Lidar odometry and mapping in real-time](https://www.ri.cmu.edu/pub_files/2014/7/Ji_LidarMapping_RSS2014_v8.pdf)|---|non-official A-LOAM<br>[![Github stars](https://img.shields.io/github/stars/HKUST-Aerial-Robotics/A-LOAM.svg)](https://github.com/HKUST-Aerial-Robotics/A-LOAM)|


* Public dataset for legged robot:

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->
| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`RSS`|[Boxi: Design Decisions in the Context of Algorithmic Performance for Robotics](https://arxiv.org/pdf/2504.18500)|[![Github stars](https://img.shields.io/github/stars/leggedrobotics/grand_tour_dataset.svg)](https://github.com/leggedrobotics/grand_tour_dataset)|[website](https://grand-tour.leggedrobotics.com/)|
|2025|`IJRR`|[Fusionportablev2: A unified multi-sensor dataset for generalized slam across diverse platforms and scalable environments](https://journals.sagepub.com/doi/pdf/10.1177/02783649241303525)|---|[website](https://fusionportable.github.io/dataset/fusionportable_v2/)|
|2025|`ICRA`|[Diter++: Diverse terrain and multi-modal dataset for multi-robot slam in multi-session environments](https://arxiv.org/pdf/2412.05839)|[![Github stars](https://img.shields.io/github/stars/sparolab/DiTer-plusplus.svg)](https://github.com/sparolab/DiTer-plusplus)|[dataset website](https://sites.google.com/view/diter-plusplus/)|
|2024|`RAL`|[CEAR: Comprehensive Event Camera Dataset for Rapid Perception of Agile Quadruped Robots](https://arxiv.org/pdf/2404.04698)|---|[website](https://daroslab.github.io/cear/)| 
|2024|`IEEE Sensors Letters`|[Diter: Diverse terrain and multimodal dataset for field robot navigation in outdoor environments](https://construction-robots.github.io/papers/37.pdf)|---|[website](https://sites.google.com/inha.edu/diter/)|
|2024|`RAL`|[Are We Ready for Planetary Exploration Robots? The TAIL-Plus Dataset for SLAM in Granular Environments](https://arxiv.org/pdf/2404.13600)|---|[websit](https://tailrobot.github.io/)|
|2023|`CVPR`|[M3ED: Multi-Robot, Multi-Sensor, Multi-Environment Event Dataset](https://openaccess.thecvf.com/content/CVPR2023W/EventVision/papers/Chaney_M3ED_Multi-Robot_Multi-Sensor_Multi-Environment_Event_Dataset_CVPRW_2023_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/daniilidis-group/m3ed.svg)](https://github.com/daniilidis-group/m3ed)|[website](https://m3ed.io/)| 
|2022|`arXiv`|[TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation](https://arxiv.org/pdf/2505.10696v1)|[![Github stars](https://img.shields.io/github/stars/castacks/tartanairpy.svg)](https://github.com/castacks/tartanairpy)|[website](https://tartanair.org/tartanground)|

# Acknowledgement
Thanks [Ji MA](https://github.com/Astrorix) for his help and advice. 


